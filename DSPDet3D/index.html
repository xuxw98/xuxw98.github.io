<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="3D Small Object Detection with Dynamic Spatial Pruning">
    <meta name="author" content="Xiuwei Xu,
                                 Zhihao Sun,
                                 Ziwei Wang,
                                 Hongmin Liu,
                                 Jie Zhou,
                                 Jiwen Lu">

    <title>3D Small Object Detection with Dynamic Spatial Pruning</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>3D Small Object Detection with Dynamic Spatial Pruning</h2>
    <h3>ECCV 2024</h3>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p>
        <span style="white-space: nowrap; font-size:larger">
        <a href="https://xuxw98.github.io/">Xiuwei Xu</a><sup>1,2*</sup>&nbsp;&nbsp;
        Zhihao Sun<sup>3*</sup>&nbsp;&nbsp;
        <a href="https://ziweiwangthu.github.io/">Ziwei Wang</a><sup>1,2</sup>&nbsp;&nbsp;
        Hongmin Liu<sup>3</sup>&nbsp;&nbsp;
        <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en&authuser=1">Jie Zhou</a><sup>1,2</sup>&nbsp;&nbsp;
        <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a><sup>1,2&#8224;</sup>
        </span>
        <br><br>
        <sup>1</sup>Department of Automation, Tsinghua University<br>
        <sup>2</sup>Beijing National Research Center for Information Science and Technology, China<br>
        <sup>3</sup>The School of Intelligence Science and Technology, University of Science and Technology Beijing<br>
        <br><br>
        <a href="https://arxiv.org/abs/2305.03716" target="_blank" style="color: #1E90FF;">
            <img src="https://img.icons8.com/material-outlined/24/000000/file.png" alt="paper" style="vertical-align: middle;">
            &nbsp;Paper (arXiv)
        </a>&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://github.com/xuxw98/DSPDet3D" target="_blank" style="color: #1E90FF;">
            <img src="https://img.icons8.com/material-outlined/24/000000/github.png" alt="code" style="vertical-align: middle;">
            &nbsp;Code (GitHub)
        </a>
    </p>

    <!-- <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/abs/2006.09661">Paper</a>
        <a class="btn btn-primary" href="https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb">Colab Notebook</a>
        <a class="btn btn-primary" href="https://dcato98.github.io/playground/#activation=sine">Tensorflow Playground</a>
        <a class="btn btn-primary" href="https://github.com/vsitzmann/siren">Code</a>
        <a class="btn btn-primary" href="https://drive.google.com/drive/u/1/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K">Data</a>
    </div> -->
</div>

<div class="container">
    <div class="vcontainer">
        <iframe class='video' src="https://www.youtube.com/embed/Wq-cIRnKhw0" frameborder="0"
                allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
    </div>

    <div class="section">
        <h2>Abstract</h2>
        <hr>
        <p>
            In this paper, we propose an efficient feature pruning strategy for 3D small object detection. Conventional 3D object detection methods struggle on small objects due to the weak geometric information from a small number of points. Although increasing the spatial resolution of feature representations can improve the detection performance on small objects, the additional computational overhead is unaffordable.
With in-depth study, we observe the growth of computation mainly comes from the upsampling operation in the decoder of 3D detector. Motivated by this, we present a multi-level 3D detector named DSPDet3D which benefits from high spatial resolution to achieves high accuracy on small object detection, while reducing redundant computation by only focusing on small object areas. Specifically, we theoretically derive a dynamic spatial pruning (DSP) strategy to prune the redundant spatial representation of 3D scene in a cascade manner according to the distribution of objects. Then we design DSP module following this strategy and construct DSPDet3D with this efficient module. On ScanNet and TO-SCENE dataset, our method achieves leading performance on small object detection. Moreover, DSPDet3D trained with only ScanNet rooms can generalize well to scenes in larger scale. It takes less than 2s to directly process a whole building consisting of more than 4500k points while detecting out almost all objects, ranging from cups to beds, on a single RTX 3090 GPU.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/teaser2.png" alt="pipeline" width="100%">
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Approach</h2>
        <hr>
        <p>
            Through in-depth analysis, we summarize three key points for designing an effective and efficient 3D detector for small object detection: (1) multi-level FPN-like architecture; (2) increasing the spatial resolution; (3) removing the useless computation in upsampling layers. To this end, we derive an optimal pruning strategy and propose DSPDet3D.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/pipeline.png" alt="pipeline" width="90%">
            </div>
        </div>
        <p>
            <b>Illustration of DSPDet3D.</b> The voxelized point clouds are fed into a high-resolution sparse convolutional backbone, which output four levels of scene representations. Four dynamic spatial pruning (DSP) modules are stacked to construct a multi-level decoder and detect objects from coarse to fine. DSP module utilizes a light-weight learnable module to predict the pruning mask. During inference, we discretize the pruning mask and use it to guide pruning before generative upsampling. While during training we interpolate the pruning mask to next level and prune the voxel features after generative upsampling.
        </p>
    </div>

    <div class="section">
        <h2>Experiments</h2>
        <hr>
        <p>
            We organize two benchmarks on ScanNet and TO-SCENE datasets for 3D small object detection.
        </p>
        <!-- add a image here-->
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/exp_v2.png" alt="pipeline" width="90%">
            </div>
        </div>
        <p>
            We compare our method with popular and state-of-the-art 3D object detection methods. As shown above, DSPDet3D with a proper threshold takes advantage of the high-resolution scene representation to achieve much higher performance. Furthermore, DSPDet3D is the most memory-efficient model among all mainstream methods.
        </p>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
            <div class="bibtexsection">
        @article{xu2023dsp, 
            title={3D Small Object Detection with Dynamic Spatial Pruning}, 
            author={Xiuwei Xu and Zhihao Sun and Ziwei Wang and Hongmin Liu and Jie Zhou and Jiwen Lu},
            journal={arXiv preprint arXiv:2305.03716},
            year={2023}
        }
            </div>
        </div>
    </div>

    <hr>

    <footer>
        <!-- <h6>Acknowledgement</h6> -->
        <p><small>The website template was borrowed from <a href="https://liuff19.github.io/S-Ray/">Fangfu Liu</a></small></p>
    </footer>
</div>

    <p><center>
        <div id="clustrmaps-widget" style="width:30%">
            <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=eRnCB4-HrSw_k86xQMK_G8k71J2xtdHboK6TdVmh9pQ&cl=ffffff&w=a"></script>    
        </div>        
        <br>
        &copy; Xiuwei Xu | Last update: June. 4, 2023
    </center></p>

<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
